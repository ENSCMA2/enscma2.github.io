---
layout: about
title: About
permalink: /
subtitle: CMU LTI | Harvard CS + History

profile:
  address: >
    <p> Image Description: Karina (white skin, brown hair, black top) smiling at the camera outside. Picture credits: Oriana Li Halevy, 2022. </p>
  align: right
  image: headshot_2022.jpg
  image_circular: false  

news: false  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

Hello! My name is Karina, and I am a PhD student at the Carnegie Mellon University Language Technologies Institute, supported by a National Science Foundation Graduate Research Fellowship! I am co-advised by [Mona Diab](https://www.lti.cs.cmu.edu/people/faculty/diab-mona.html) and [Maarten Sap](https://maartensap.com/). Previously, I got my undergrad degree in Computer Science and History with a minor in Statistics from Harvard College, where I worked with Professors [Stuart Shieber](https://www.eecs.harvard.edu/shieber/), [Elena Glassman](https://glassmanlab.seas.harvard.edu/glassman.html), [Cemal Kafadar](https://history.fas.harvard.edu/people/cemal-kafadar), and [Dami√°n Blasi](https://www.damianblasi.org/). I have also spent summers working with [Carolina Brum](https://www.carolinabrum.com/) (Apple), [Antoine Bosselut](https://atcbosselut.github.io/), [Syrielle Montariol](https://smontariol.github.io/) (EPFL), and [Jordan Hashemi](https://scholar.google.com/citations?user=GIMzJq4AAAAJ&hl=en) (BBN Technologies). My main academic interest is in **natural language processing/computational linguistics**.

I am specifically interested in:  
- constructing evaluation metrics and benchmark datasets to make large language models more understandable (e.g. what linguistic information are they really capturing, what latent biases do they have, why does model x perform better than model y on task z)  
- doing NLP for low-resource/non-Indo-European languages  
- *carefully* doing NLP for social science/social good (e.g. information extraction or visualization for long legal/medical/historical texts, hate speech detection)  
- algorithmic fairness/ethics (especially for disabled people, ethnically minoritized people, & people who are marginalized in multiple ways)  
- intersections of NLP with human-computer interaction and data visualization  

I also [dance](/dance).

